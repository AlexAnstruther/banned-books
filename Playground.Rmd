---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Compas Analysis


## Importing Libraries

```{python}
# %run -i projtools/imports.py
```

## Loading Data

```{python}
# %run -i projtools/data.py
```

## 'df' Descriptive Statistics

```{python}
df['length_of_stay'] = (pd.to_numeric(pd.to_datetime(df['c_jail_out'])) - pd.to_numeric(pd.to_datetime(df['c_jail_in'])))
df[['length_of_stay','decile_score']].corr().iloc[0,1]
```

```{python}
display(df['age_cat'].value_counts(),
    df['race'].value_counts(),
    df['race'].value_counts().apply(lambda x : x / len(df) * 100),
    df['score_text'].value_counts(),
    pd.crosstab(df['sex'],df['race']),
    df['sex'].value_counts(),
    df['sex'].value_counts().apply(lambda x : x / len(df) * 100),
    len(df[df['two_year_recid'] == 1]),
    len(df[df['two_year_recid'] == 1]) / len(df) * 100,
    pd.crosstab(df['decile_score'],df['race']))
```

```{python}
#using groupby to create a table which can be turned into a barchart
df['Index'] = df.index
african_american_barchart = df[df['race'] == 'African-American'].groupby(['decile_score'])['Index'].unique().apply(len)
caucasian_barchart = df[df['race'] == 'Caucasian'].groupby(['decile_score'])['Index'].unique().apply(len)
df = df.drop(['Index'],axis=1)
```

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))

#format for barchart_setting(axes1,axes2,upper_ylim)
graph_formats.barchart_setting(ax1,ax2,620)

ax1.bar(african_american_barchart.index,african_american_barchart.values,color='dimgrey',zorder=2)
ax1.set_title("Black Defendent's Decile Scores")
ax2.bar(caucasian_barchart.index,caucasian_barchart.values,color='dimgrey',zorder=2)
ax2.set_title("White Defendent's Decile Scores");
```

```{python}
df['Index'] = df.index
african_american_barchart = df[df['race'] == 'African-American'].groupby(['decile_score'])['Index'].unique().apply(len)
caucasian_barchart = df[df['race'] == 'Caucasian'].groupby(['decile_score'])['Index'].unique().apply(len)
```

```{python}
df['Index'] = df.index

```

```{python}
model = smf.logit(formula='score_text_low_high_HighScore ~ sex_Female + age_cat_Less_than_25 + age_cat_Greater_than_45 + race_African_American + race_Asian + race_Hispanic + race_Native_American + race_Other + priors_count + c_charge_degree_M + two_year_recid', data=df).fit()
display(model.summary())
```

## DO NOT FORGET TO DO LOG ODDS HERE


## Calculating Odds Ratios
Why did they do this so differently?
Does it matter - or can we back up what we are saying here?

```{python}
#converting log-odds to odds
odds_baselevel = np.exp(model.params.Intercept)
odds_black = np.exp(model.params.race_African_American)

#calculating an odds ratio
display(f"Using an odds ratio, black defendants are " + str(odds_black/odds_baselevel * 100)[:3] + "% more likely to receive a high score than white defendants.")
```

```{python}
odds_female = np.exp(model.params.sex_Female)
display(f"Using an odds ratio, female defendants are " + str(odds_female/odds_baselevel * 100)[:3] + "% more likely to receive a high score than male defendants.")
```

```{python}
odds_under25 = np.exp(model.params.age_cat_Less_than_25) / (1 + np.exp(model.params.age_cat_Less_than_25))
odds_over45 = np.exp(model.params.age_cat_Greater_than_45) / (1 + np.exp(model.params.age_cat_Greater_than_45))
display(f"Using an odds ratio, defendants under 25 are " + str(odds_under25/odds_baselevel * 100)[:3] + "% more likely to receive a high score than defendants between 25 and 45.")
display(f"Using an odds ratio, defendants over 45 are " + str(odds_over45/odds_baselevel * 100)[:2] + "% more likely to receive a high score than defendants between 25 and 45.")

```

## 'violent_df' Descriptive Statistics

```{python}
display(violent_df['age_cat'].value_counts(),
    violent_df['race'].value_counts(),
    violent_df['v_score_text'].value_counts(),
    len(violent_df[violent_df['two_year_recid'] == 1]),
    len(violent_df[violent_df['two_year_recid'] == 1]) / len(violent_df) * 100)
```

```{python}
violent_df['Index'] = violent_df.index
v_african_american_barchart = violent_df[violent_df['race'] == 'African-American'].groupby(['v_decile_score'])['Index'].unique().apply(len)
v_caucasian_barchart = violent_df[violent_df['race'] == 'Caucasian'].groupby(['v_decile_score'])['Index'].unique().apply(len)
violent_df = violent_df.drop(['Index'],axis=1)
```

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))

graph_formats.barchart_setting(ax1,ax2,700)

ax1.bar(v_african_american_barchart.index,v_african_american_barchart.values,color='dimgrey',zorder=2)
ax1.set_title("Black Defendent's Violent Decile Scores")
ax2.bar(v_caucasian_barchart.index,v_caucasian_barchart.values,color='dimgrey',zorder=2)
ax2.set_title("White Defendent's Violent Decile Scores");
```

```{python}
violent_df.columns
```

```{python}
model = smf.logit(formula='v_score_text_low_high_HighScore ~ sex_Female + age_cat_Less_than_25 + age_cat_Greater_than_45 + race_African_American + race_Asian + race_Hispanic + race_Native_American + race_Other + priors_count + c_charge_degree_M + two_year_recid', data=violent_df).fit()
print(model.summary())
```

## 'cox_df' Descriptive Statistics

```{python}
display(cox_df['score_text'].value_counts(),
    cox_df['race'].value_counts())
```

## Predictive Accuracy of COMPAS

```{python}
from itertools import combinations
recid_by_size = cox_df.groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size.loc['HighMedium'] = recid_by_size.loc['High'] + recid_by_size.loc['Medium']
recid_by_size['percent'] = recid_by_size['sum']/recid_by_size['size']
display(f"HighMedium vs Low: {recid_by_size.loc['HighMedium','percent']/recid_by_size.loc['Low','percent']}",
    f"High vs Low: {recid_by_size.loc['High','percent']/recid_by_size.loc['Low','percent']}",
    f"Text concordance: {conc.concordance_text_score(cox_df,['is_recid','score_text'],100)}")
```

```{python}
display(f"Decile concordance: {conc.concordance_decile_score(cox_df,['is_recid','decile_score'],100)}")
```

```{python}
recid_by_size_black = cox_df[cox_df['race'] == 'African-American'].groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size_black['percent'] = recid_by_size_black['sum']/recid_by_size_black['size']
recid_by_size_white = cox_df[cox_df['race'] == 'Caucasian'].groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size_white['percent'] = recid_by_size_white['sum']/recid_by_size_white['size']
display(f"High vs Low (African-American): {recid_by_size_black.loc['High','percent']/recid_by_size_black.loc['Low','percent']}",
        f"High vs Low (Caucasian): {recid_by_size_white.loc['High','percent']/recid_by_size_white.loc['Low','percent']}")
```

# Add Recidivism Line Graph for whole pop.

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
cox_df_black = cox_df[cox_df['race'] == 'African-American']
cox_df_white = cox_df[cox_df['race'] == 'Caucasian']

for score, color in zip(['Low', 'Medium', 'High'], ['green', 'orange', 'red']):
    subset = cox_df_white[(cox_df_white['is_recid'] == 1) & (cox_df_white['score_text'] == score)]
    total_count = len(cox_df_white[cox_df_white['score_text'] == score])
    value_counts = subset['duration'].value_counts().sort_index().cumsum()
    proportion = (total_count - value_counts) / total_count
    proportion.plot(ax=ax1, color=color, label=score, title='White')

ax1.set_ylim([0, 1])
ax1.set_ylabel('Proportion Not Recidivised')
ax1.set_xlabel('Days')
ax1.legend()
ax1.grid()

for score, color in zip(['Low', 'Medium', 'High'], ['green', 'orange', 'red']):
    subset = cox_df_black[(cox_df_black['is_recid'] == 1) & (cox_df_black['score_text'] == score)]
    total_count = len(cox_df_black[cox_df_black['score_text'] == score])
    value_counts = subset['duration'].value_counts().sort_index().cumsum()
    proportion = (total_count - value_counts) / total_count
    proportion.plot(ax=ax2, color=color, label=score, title='Black')

ax2.set_ylim([0, 1])
ax2.set_ylabel('Proportion Not Recidivised')
ax2.set_xlabel('Days')
ax2.legend(loc='lower left')
ax2.grid()
```

# Do White and Black Race Line Graph for violent scores

```{python}
display(f"Violent Text concordance: {conc.concordance_text_score(cox_df,['is_recid','score_text'],100)}")
```

# Directions of the Racial Bias


Realised what is_recid is vs event - is_recid is whether someone has recidivised while event only increases to one, once per person. This means is_recid can have multiple values for the same person when they have only recidivised once

```{python}
#create class called person
df = pd.read_csv('CompasAnalysis/cox-parsed.csv')
    
#checking the differences between two rows with the same person
differences = df.iloc[3].dropna() != df.iloc[4].dropna()
print(differences[differences].index)
```

```{python}
#this finds the total lifetime per person
lifetimes =  df.groupby('id')[['start','end']].sum().apply(lambda x: x['end'] - x['start'], axis=1)

#removing duplicate ID rows
df = df[~df['id'].duplicated(keep='first')]

df['lifetime'] = lifetimes.values

#if recidivist filter lifetimes so only contains people under two years - otherwise contain people who did not recidivise for over two years
df = df[((df['lifetime'] <= 730) & (df['is_recid'] == 1)) | (df['lifetime'] > 730)]
```

```{python}
#creating my own confusion matrices
is_recid = (df['is_recid'] == 1) & (df['lifetime'] <= 730)
is_not_recid = (df['lifetime'] > 730)
score_high = (df['score_text'] == 'High') | (df['score_text'] == 'Medium')
score_low = df['score_text'] == 'Low'
df['truth_table_recid'] = np.select([is_not_recid, is_recid], ['Survivor','Recidivist'], default=np.nan)
df['truth_table_score'] = np.select([score_low, score_high], ['Survivor','Recidivist'], default=np.nan)
```

```{python}
cm_df = df[['id','race','truth_table_recid','truth_table_score']]
cm_df = cm_df.dropna(subset=['truth_table_recid','truth_table_score'])
cm = confusion_matrix(y_true=cm_df['truth_table_recid'],y_pred=cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.4,-0.6,'Confusion Matrix - All Defendants', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"Total pop: {(2681 + 1282 + 1216 + 2035)}")
print(f"Overall the false positive rate is {1282/(2681 + 1282)}")
#there are slightly different survivor figures compared to pro publica
```

```{python}
display(f"The mean time between release and re-entry of custody is {np.mean(df['lifetime'])} days (stdev: {np.std(df['lifetime'])} days.)")
display(f"The median time between release and re-entry of custody is {np.median(df['lifetime'])} days.")
#different figures again
```

```{python}
black_cm_df = cm_df[cm_df['race'] == 'African-American']
cm = confusion_matrix(y_true=black_cm_df['truth_table_recid'],y_pred=black_cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.55,-0.6,'Confusion Matrix - Black Defendants', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"For black defendants, the false positive rate is {805/(990 + 805)}")
```

```{python}
white_cm_df = cm_df[cm_df['race'] == 'Caucasian']
cm = confusion_matrix(y_true=white_cm_df['truth_table_recid'],y_pred=white_cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.55,-0.6,'Confusion Matrix - White Defendants', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"For white defendants, the false positive rate is {349/(349 + 1139)}")
print(f"Therefore, black defendants are {round(((805/(990 + 805))/(349/(349 + 1139)) - 1) * 100,2)}% more likely to receive a High COMPAS score and not recidivise within 2 years (false \npositive) than white defendants.")
print(f"Furthermore, white defendants are {round(((461/(461 + 505))/(532/(532 + 1369)) - 1) * 100,2)}% more likely to receive a Low COMPAS score yet still recidivise within 2 years (false \nnegative) than black defendants.")
```

## Risk of Violent Recidivism

```{python}
#reading in cox-violent-parsed
v_df = pd.read_csv('CompasAnalysis/cox-violent-parsed.csv')   
```

```{python}
#this finds the total lifetime per person
lifetimes_df =  pd.DataFrame(v_df.groupby('id')[['start','end']].sum().apply(lambda x: x['end'] - x['start'], axis=1)).rename(columns={0:'lifetime'})
lifetimes = lifetimes_df['lifetime']

#removing duplicate ID rows
v_df = v_df[~v_df['id'].duplicated(keep='first')]

v_df['lifetime'] = lifetimes

#if recidivist filter lifetimes so only contains people under two years - otherwise contain people who did not recidivise for over two years
v_df = v_df[((v_df['lifetime'] <= 730) & (v_df['is_violent_recid'] == 1)) | (v_df['lifetime'] > 730)]
```

```{python}
#creating conditions to define the scores someone gets in the confusion matrix
#in reality recidivised within two years
is_recid = (v_df['is_violent_recid'] == 1) & (v_df['lifetime'] <= 730)
#in reality did not recidivise within two years
is_not_recid = (v_df['lifetime'] > 730)
#predicted to recidivise
score_high = (v_df['v_score_text'] == 'High') | (v_df['v_score_text'] == 'Medium')
#predicted to not recidivise
score_low = v_df['v_score_text'] == 'Low'

#applying the conditions to create new prediction and true columns with survivor and recidivist values
v_df['truth_table_recid'] = np.select([is_not_recid, is_recid], ['Survivor','Recidivist'], default=np.nan)
v_df['truth_table_score'] = np.select([score_low, score_high], ['Survivor','Recidivist'], default=np.nan)
```

```{python}
#creating smaller df for our confusion matrices
v_cm_df = v_df[['id','race','truth_table_recid','truth_table_score']]
v_cm_df = v_cm_df.dropna(subset=['truth_table_recid','truth_table_score'])

#setting up confusion matrix
cm = confusion_matrix(y_true=v_cm_df['truth_table_recid'],y_pred=v_cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.2,-0.6,'All Defendants - Violent', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"Overall for violent recidivism, the false positive rate is {1088/(1088 + 2350)}")
```

```{python}
v_black_cm_df = v_cm_df[v_cm_df['race'] == 'African-American']
cm = confusion_matrix(y_true=v_black_cm_df['truth_table_recid'],y_pred=v_black_cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.25,-0.6,'Black Defendants - Violent', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"For violent recidivism in black defendants, the false positive rate is {743/(743 + 974)}")
```

```{python}
v_white_cm_df = v_cm_df[v_cm_df['race'] == 'Caucasian']
cm = confusion_matrix(y_true=v_white_cm_df['truth_table_recid'],y_pred=v_white_cm_df['truth_table_score'],labels=['Survivor','Recidivist'])
fig = ConfusionMatrixDisplay(cm,display_labels=['Survivor','Recidivist'])
fig.plot(cmap=plt.cm.Blues)
plt.text(-0.2,-0.6,'White Defendants - Violent', fontdict={'weight': 'bold', 'size': 16});
```

```{python}
print(f"For violent recidivism in white defendants, the false positive rate is {243/(243 + 963)}")
print(f"Therefore, black defendants are {round(((743/(743 + 974))/(243/(243 + 963)) - 1) * 100,2)}% more likely to receive a High Violence COMPAS score and not violently recidivise \nwithin 2 years (false positive) than white defendants.")
print(f"Furthermore, white defendants are {round(((48/(48 + 23))/(53/(53 + 95)) - 1) * 100,2)}% more likely to receive a Low Violence COMPAS score yet still violently recidivise \nwithin 2 years (false negative) than black defendants.")
```
