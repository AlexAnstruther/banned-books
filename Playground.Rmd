---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Compas Analysis


## Importing Libraries

```{python}
# %run -i projtools/imports.py
```

## Loading Data

```{python}
# %run -i projtools/data.py
```

## 'df' Descriptive Statistics

```{python}
df['length_of_stay'] = (pd.to_numeric(pd.to_datetime(df['c_jail_out'])) - pd.to_numeric(pd.to_datetime(df['c_jail_in'])))
df[['length_of_stay','decile_score']].corr().iloc[0,1]
```

```{python}
display(df['age_cat'].value_counts(),
    df['race'].value_counts(),
    df['race'].value_counts().apply(lambda x : x / len(df) * 100),
    df['score_text'].value_counts(),
    pd.crosstab(df['sex'],df['race']),
    df['sex'].value_counts(),
    df['sex'].value_counts().apply(lambda x : x / len(df) * 100),
    len(df[df['two_year_recid'] == 1]),
    len(df[df['two_year_recid'] == 1]) / len(df) * 100,
    pd.crosstab(df['decile_score'],df['race']))
```

```{python}
#using groupby to create a table which can be turned into a barchart
df['Index'] = df.index
african_american_barchart = df[df['race'] == 'African-American'].groupby(['decile_score'])['Index'].unique().apply(len)
caucasian_barchart = df[df['race'] == 'Caucasian'].groupby(['decile_score'])['Index'].unique().apply(len)
df = df.drop(['Index'],axis=1)
```

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))

#format for barchart_setting(axes1,axes2,upper_ylim)
graph_formats.barchart_setting(ax1,ax2,620)

ax1.bar(african_american_barchart.index,african_american_barchart.values,color='dimgrey',zorder=2)
ax1.set_title("Black Defendent's Decile Scores")
ax2.bar(caucasian_barchart.index,caucasian_barchart.values,color='dimgrey',zorder=2)
ax2.set_title("White Defendent's Decile Scores");
```

```{python}
df['Index'] = df.index
african_american_barchart = df[df['race'] == 'African-American'].groupby(['decile_score'])['Index'].unique().apply(len)
caucasian_barchart = df[df['race'] == 'Caucasian'].groupby(['decile_score'])['Index'].unique().apply(len)
```

```{python}
df['Index'] = df.index

```

```{python}
model = smf.logit(formula='score_text_low_high_HighScore ~ sex_Female + age_cat_Less_than_25 + age_cat_Greater_than_45 + race_African_American + race_Asian + race_Hispanic + race_Native_American + race_Other + priors_count + c_charge_degree_M + two_year_recid', data=df).fit()
display(model.summary())
```

## DO NOT FORGET TO DO LOG ODDS HERE


## Calculating Odds Ratios
Why did they do this so differently?
Does it matter - or can we back up what we are saying here?

```{python}
#converting log-odds to odds
odds_baselevel = np.exp(model.params.Intercept)
odds_black = np.exp(model.params.race_African_American)

#calculating an odds ratio
display(f"Using an odds ratio, black defendants are " + str(odds_black/odds_baselevel * 100)[:3] + "% more likely to receive a high score than white defendants.")
```

```{python}
odds_female = np.exp(model.params.sex_Female)
display(f"Using an odds ratio, female defendants are " + str(odds_female/odds_baselevel * 100)[:3] + "% more likely to receive a high score than male defendants.")
```

```{python}
odds_under25 = np.exp(model.params.age_cat_Less_than_25) / (1 + np.exp(model.params.age_cat_Less_than_25))
odds_over45 = np.exp(model.params.age_cat_Greater_than_45) / (1 + np.exp(model.params.age_cat_Greater_than_45))
display(f"Using an odds ratio, defendants under 25 are " + str(odds_under25/odds_baselevel * 100)[:3] + "% more likely to receive a high score than defendants between 25 and 45.")
display(f"Using an odds ratio, defendants over 45 are " + str(odds_over45/odds_baselevel * 100)[:2] + "% more likely to receive a high score than defendants between 25 and 45.")

```

## 'violent_df' Descriptive Statistics

```{python}
display(violent_df['age_cat'].value_counts(),
    violent_df['race'].value_counts(),
    violent_df['v_score_text'].value_counts(),
    len(violent_df[violent_df['two_year_recid'] == 1]),
    len(violent_df[violent_df['two_year_recid'] == 1]) / len(violent_df) * 100)
```

```{python}
violent_df['Index'] = violent_df.index
v_african_american_barchart = violent_df[violent_df['race'] == 'African-American'].groupby(['v_decile_score'])['Index'].unique().apply(len)
v_caucasian_barchart = violent_df[violent_df['race'] == 'Caucasian'].groupby(['v_decile_score'])['Index'].unique().apply(len)
violent_df = violent_df.drop(['Index'],axis=1)
```

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))

graph_formats.barchart_setting(ax1,ax2,700)

ax1.bar(v_african_american_barchart.index,v_african_american_barchart.values,color='dimgrey',zorder=2)
ax1.set_title("Black Defendent's Violent Decile Scores")
ax2.bar(v_caucasian_barchart.index,v_caucasian_barchart.values,color='dimgrey',zorder=2)
ax2.set_title("White Defendent's Violent Decile Scores");
```

```{python}
violent_df.columns
```

```{python}
model = smf.logit(formula='v_score_text_low_high_HighScore ~ sex_Female + age_cat_Less_than_25 + age_cat_Greater_than_45 + race_African_American + race_Asian + race_Hispanic + race_Native_American + race_Other + priors_count + c_charge_degree_M + two_year_recid', data=violent_df).fit()
print(model.summary())
```

## 'cox_df' Descriptive Statistics

```{python}
display(cox_df['score_text'].value_counts(),
    cox_df['race'].value_counts())
```

## Predictive Accuracy of COMPAS

```{python}
from itertools import combinations
recid_by_size = cox_df.groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size.loc['HighMedium'] = recid_by_size.loc['High'] + recid_by_size.loc['Medium']
recid_by_size['percent'] = recid_by_size['sum']/recid_by_size['size']
display(f"HighMedium vs Low: {recid_by_size.loc['HighMedium','percent']/recid_by_size.loc['Low','percent']}",
    f"High vs Low: {recid_by_size.loc['High','percent']/recid_by_size.loc['Low','percent']}",
    f"Text concordance: {conc.concordance_text_score(cox_df,['is_recid','score_text'],100)}")
```

```{python}
display(f"Decile concordance: {conc.concordance_decile_score(cox_df,['is_recid','decile_score'],100)}")
```

```{python}
recid_by_size_black = cox_df[cox_df['race'] == 'African-American'].groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size_black['percent'] = recid_by_size_black['sum']/recid_by_size_black['size']
recid_by_size_white = cox_df[cox_df['race'] == 'Caucasian'].groupby('score_text')['is_recid'].agg(['sum','size'])
recid_by_size_white['percent'] = recid_by_size_white['sum']/recid_by_size_white['size']
display(f"High vs Low (African-American): {recid_by_size_black.loc['High','percent']/recid_by_size_black.loc['Low','percent']}",
        f"High vs Low (Caucasian): {recid_by_size_white.loc['High','percent']/recid_by_size_white.loc['Low','percent']}")
```

# Add Recidivism Line Graph for whole pop.

```{python}
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
cox_df_black = cox_df[cox_df['race'] == 'African-American']
cox_df_white = cox_df[cox_df['race'] == 'Caucasian']

for score, color in zip(['Low', 'Medium', 'High'], ['green', 'orange', 'red']):
    subset = cox_df_white[(cox_df_white['is_recid'] == 1) & (cox_df_white['score_text'] == score)]
    total_count = len(cox_df_white[cox_df_white['score_text'] == score])
    value_counts = subset['duration'].value_counts().sort_index().cumsum()
    proportion = (total_count - value_counts) / total_count
    proportion.plot(ax=ax1, color=color, label=score, title='White')

ax1.set_ylim([0, 1])
ax1.set_ylabel('Proportion Not Recidivised')
ax1.set_xlabel('Days')
ax1.legend()
ax1.grid()

for score, color in zip(['Low', 'Medium', 'High'], ['green', 'orange', 'red']):
    subset = cox_df_black[(cox_df_black['is_recid'] == 1) & (cox_df_black['score_text'] == score)]
    total_count = len(cox_df_black[cox_df_black['score_text'] == score])
    value_counts = subset['duration'].value_counts().sort_index().cumsum()
    proportion = (total_count - value_counts) / total_count
    proportion.plot(ax=ax2, color=color, label=score, title='Black')

ax2.set_ylim([0, 1])
ax2.set_ylabel('Proportion Not Recidivised')
ax2.set_xlabel('Days')
ax2.legend(loc='lower left')
ax2.grid()
```

# Do White and Black Race Line Graph for violent scores

```{python}
display(f"Violent Text concordance: {conc.concordance_text_score(cox_df,['is_recid','score_text'],100)}")
```

# Next Section: Directions of the Racial Bias


Realised what is_recid is vs event - is_recid is whether someone has recidivised while event only increases to one, once per person. This means is_recid can have multiple values for the same person when they have only recidivised once

```{python}
#create class called person
df = pd.read_csv('CompasAnalysis/cox-parsed.csv')
    
#checking the differences between two rows with the same person
differences = df.iloc[3].dropna() != df.iloc[4].dropna()
print(differences[differences].index)
    
#this finds the total lifetime per row
lifetimes =  df.groupby('id')[['start','end']].sum().apply(lambda x: x['end'] - x['start'], axis=1)
lifetimes_df = pd.DataFrame({'id': lifetimes.index, 'lifetimes': lifetimes.values})
lifetimes_df
```

```{python}
#removing duplicate ID rows
filtered_df = df[~df['id'].duplicated(keep='first')]
filtered_df['lifetimes'] = lifetimes_df['lifetimes']
```

```{python}
df.groupby('id')['event'].unique().apply(len)
```

```{python}
df.columns
```

```{python}
from CompasAnalysis import truth_tables
from csv import DictReader

people = []
with open("CompasAnalysis/cox-parsed.csv") as f:
    reader = truth_tables.PeekyReader(DictReader(f))
    try:
        while True:
            p = truth_tables.Person(reader)
            if p.valid:
                people.append(p)
    except StopIteration:
        pass

pop = list(filter(lambda i: ((i.recidivist == True and i.lifetime <= 730) or
                              i.lifetime > 730), list(filter(lambda x: x.score_valid, people))))
recid = list(filter(lambda i: i.recidivist == True and i.lifetime <= 730, pop))
rset = set(recid)
surv = [i for i in pop if i not in rset]



```

```{python}
print("All defendants")
truth_tables.table(list(recid), list(surv))
```

```{python}
print(f"Total pop: {(2681 + 1282 + 1216 + 2035)}")
```

```{python}
print("Average follow-up time %.2f (sd %.2f)" % (statistics.mean(map(lambda i: i.lifetime, pop)),
                                                statistics.stdev(map(lambda i: i.lifetime, pop))))
print("Median follow-up time %i" % (statistics.median(map(lambda i: i.lifetime, pop))))
```

```{python}
print("Black defendants")
is_afam = truth_tables.is_race("African-American")
truth_tables.table(list(filter(is_afam, recid)), list(filter(is_afam, surv)))
```

```{python}
print("White defendants")
is_white = truth_tables.is_race("Caucasian")
truth_tables.table(list(filter(is_white, recid)), list(filter(is_white, surv)))
```

```{python}
44.85 / 23.45
```
